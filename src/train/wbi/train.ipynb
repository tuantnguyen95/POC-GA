{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for training. We used the famous apps as the training dataset for model v1.\n",
    "'''\n",
    "Update path of dataset below\n",
    "'''\n",
    "data_path = '/Users/phuongle/MyProjects/kobiton/tools/what-beautiful-is/dataset-train/'\n",
    "data = []\n",
    "data_columns = ['']\n",
    "for file in os.listdir(data_path):\n",
    "  if 'dataset_normal_' in file:\n",
    "    df = pd.read_csv(data_path + file)\n",
    "    for row in df.iterrows():\n",
    "      label1 = row[1]['A_over_B_label']\n",
    "      label2 = row[1]['B_over_A_label']\n",
    "      if label1 == label2:\n",
    "        coordA = [int(x) for x in row[1]['screen_A_coordinate_element'][1:-1].split(',')]\n",
    "        coordB = [int(x) for x in row[1]['screen_B_coordinate_element'][1:-1].split(',')]\n",
    "        r = [row[1]['screen_A_fontsize_mm'], row[1]['screen_A_width'], row[1]['screen_A_height'], \n",
    "             row[1]['screen_A_ppi'], coordA[0], coordA[1], row[1]['screen_B_fontsize_mm'], row[1]['screen_B_width'], \n",
    "             row[1]['screen_B_height'], row[1]['screen_B_ppi'], coordB[0], coordB[1], label1]\n",
    "        data.append(r)\n",
    "with gzip.open('data.pklz', \"wb\") as f:\n",
    "  pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for testing. We used the normal apps as the testing dataset for model v1\n",
    "'''\n",
    "Update file path of dataset below\n",
    "'''\n",
    "data_path = ''\n",
    "df = pd.read_csv('/Users/phuongle/MyProjects/kobiton/tools/what-beautiful-is/dataset-test/normal_apps.csv')\n",
    "data = []\n",
    "for row in df.iterrows():\n",
    "  label1 = row[1]['A_over_B_label']\n",
    "  label2 = row[1]['B_over_A_label']\n",
    "  if label1 == label2 and label1 != -1:\n",
    "    coordA = [int(x) for x in row[1]['screen_A_coordinate_element'][1:-1].split(',')]\n",
    "    coordB = [int(x) for x in row[1]['screen_B_coordinate_element'][1:-1].split(',')]\n",
    "    r = [row[1]['screen_A_fontsize_mm'], row[1]['screen_A_width'], row[1]['screen_A_height'], \n",
    "        row[1]['screen_A_ppi'], coordA[0], coordA[1], row[1]['screen_B_fontsize_mm'], row[1]['screen_B_width'], \n",
    "        row[1]['screen_B_height'], row[1]['screen_B_ppi'], coordB[0], coordB[1], label1]\n",
    "    data.append(r)\n",
    "with gzip.open('test.pklz', \"wb\") as f:\n",
    "  pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('data.pklz', 'rb') as f:\n",
    "  data_train = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 for abnormal, 0 for normal\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train = np.array(data_train)\n",
    "n = len(data_train)\n",
    "positive = np.where(data_train[:, -1] == 1)[0]\n",
    "negative = np.where(data_train[:, -1] == 0)[0]\n",
    "len_pos = len(positive)\n",
    "print(n, len(positive), len(negative))\n",
    "X = data_train[:, :-1]\n",
    "y = data_train[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune data for tree\n",
    "tree = RandomForestClassifier(n_estimators=150, min_samples_split=20, min_samples_leaf=10)\n",
    "tree.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagging\n",
    "number_models = int(len(negative)/len_pos) + 1\n",
    "models = []\n",
    "begin = 0\n",
    "for i in range(number_models):\n",
    "  idx = np.concatenate([positive, negative[begin:begin+len_pos*3]])\n",
    "  np.random.shuffle(idx)\n",
    "  X_train = X[idx]\n",
    "  y_train = y[idx]\n",
    "  tree = RandomForestClassifier(n_estimators=150, min_samples_split=20, min_samples_leaf=10)\n",
    "  tree.fit(X_train, y_train)\n",
    "  begin += len_pos\n",
    "  if begin + len_pos*3 >= len(negative):\n",
    "    begin = 0\n",
    "    np.random.shuffle(negative)\n",
    "  models.append(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear\n",
    "nn = Perceptron()\n",
    "begin = 0\n",
    "for i in range(10):\n",
    "  idx = np.concatenate([positive, negative[begin:begin+len_pos]])\n",
    "  np.random.shuffle(idx)\n",
    "  X_train = X[idx]\n",
    "  y_train = y[idx]\n",
    "  begin += len_pos\n",
    "  if begin + len_pos >= len(negative):\n",
    "    begin = 0\n",
    "    np.random.shuffle(negative)\n",
    "  nn.fit(X_train, y_train)\n",
    "# nn.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('test.pklz', 'rb') as f:\n",
    "  data_test = pickle.load(f)\n",
    "data_test = np.array(data_test)\n",
    "n = len(data_test)\n",
    "X_test = data_test[:, :-1]\n",
    "y_test = data_test[:, -1]\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "svc = SVC()\n",
    "svc.fit(np.concatenate([X, X_test]), np.concatenate([y, y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Booster\n",
    "model = LGBMClassifier(min_data_in_bin=10)\n",
    "model.fit(np.concatenate([X, X_test]), np.concatenate([y, y_test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric - Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total\n",
    "y_h = []\n",
    "for tree in models:\n",
    "  y_h.append(tree.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat = np.sum(y_h, axis=0) > len(models)-4  * 1.\n",
    "y_hat = nn.predict(X)\n",
    "# y_hat = svc.predict(X)\n",
    "n = 58126\n",
    "# y_hat = model.predict(X)\n",
    "print(accuracy_score(y, y_hat))\n",
    "tn, fp, fn, tp = confusion_matrix(y, y_hat).ravel()\n",
    "print(tn*100/n, fp*100/n, fn*100/n, tp*100/n)\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "data = np.array(data)\n",
    "n_test = len(data)\n",
    "positive_t = len(np.where(data[:, -1] == 1)[0])\n",
    "negative_t = n_test - positive_t\n",
    "print(n_test, positive_t, negative_t)\n",
    "X_test = data[:, :-1]\n",
    "y_test = data[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ht = []\n",
    "for tree in models:\n",
    "  y_ht.append(tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hatt = np.sum(y_ht, axis=0) > 0  * 1.\n",
    "y_hatt = nn.predict(X_test)\n",
    "# y_hatt = svc.predict(X_test)\n",
    "n_test = 94\n",
    "# y_hatt = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_hatt))\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_hatt).ravel()\n",
    "print(tn*100/n_test, fp*100/n_test, fn*100/n_test, tp*100/n_test)\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svc, open('fontsize_svc.pkl', 'wb'))\n",
    "pickle.dump(model, open('fontsize_lightgbm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
